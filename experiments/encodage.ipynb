{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2d4484",
   "metadata": {},
   "source": [
    "## Test de différents encodage\n",
    "\n",
    "#### Import du dataframe néttoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351d5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the librairies\n",
    "import pandas as pd\n",
    "\n",
    "# Exporting the csv file into a DataFrame pandas\n",
    "chemin_fichier = \"../data/data_cleaned.csv\"\n",
    "df = pd.read_csv(chemin_fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42aabdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mettre directement dans wrangling\n",
    "df.drop(columns='date_mutation', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec532ace",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0449b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Defining our Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "\n",
    "# Normalisation des noms de rue (supression espace majuscules)\n",
    "df['adresse_nom_voie'] = df['adresse_nom_voie'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Encoding\n",
    "encoded = encoder.fit_transform(df[['adresse_nom_voie']])\n",
    "col_names = encoder.get_feature_names_out(['adresse_nom_voie'])\n",
    "encoded_df = pd.DataFrame(encoded, columns=col_names, index=df.index)\n",
    "\n",
    "\n",
    "df_one_hot = pd.concat([df.drop(columns=['adresse_nom_voie','adresse_code_voie']), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26091985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57957, 3386)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99202c35",
   "metadata": {},
   "source": [
    "#### Enregistrement de l'encoder pour l'app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"../models/encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df5e97",
   "metadata": {},
   "source": [
    "#### Encodage entier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27938c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encodage_entier = df.drop(columns='adresse_nom_voie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831d1ea",
   "metadata": {},
   "source": [
    "#### Entrainement des deux dataframe sur un arbre des décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59f1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1765.90\n",
      "RMSE : 3210.20\n",
      "R²   : 0.2537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Creating feature\n",
    "X = df_one_hot.drop(columns='prix_au_m2')\n",
    "y = df_one_hot['prix_au_m2']\n",
    "\n",
    "# Spliting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = root_mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddb19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1804.14\n",
      "RMSE : 3352.25\n",
      "R²   : 0.1862\n"
     ]
    }
   ],
   "source": [
    "# Creating feature\n",
    "X = df_encodage_entier.drop(columns='prix_au_m2')\n",
    "y = df_encodage_entier['prix_au_m2']\n",
    "\n",
    "# Spliting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = root_mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492f3e5",
   "metadata": {},
   "source": [
    "#### Encodage arrondisement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c61aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Normaliser 'adresse_nom_voie'\n",
    "df['adresse_nom_voie'] = df['adresse_nom_voie'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Définir l'encodeur pour deux colonnes\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit-transform sur les deux colonnes\n",
    "encoded = encoder.fit_transform(df[['adresse_nom_voie', 'arrondissement']])\n",
    "col_names = encoder.get_feature_names_out(['adresse_nom_voie', 'arrondissement'])\n",
    "\n",
    "# Créer le DataFrame encodé\n",
    "encoded_df = pd.DataFrame(encoded, columns=col_names, index=df.index)\n",
    "\n",
    "# Concaténer avec le reste du DataFrame\n",
    "df_one_hot = pd.concat([\n",
    "    df.drop(columns=['adresse_nom_voie', 'adresse_code_voie', 'arrondissement']),\n",
    "    encoded_df\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be665be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7763d7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1806.75\n",
      "RMSE : 3263.39\n",
      "R²   : 0.2288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Creating feature\n",
    "X = df_one_hot.drop(columns='prix_au_m2')\n",
    "y = df_one_hot['prix_au_m2']\n",
    "\n",
    "# Spliting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = root_mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead9440",
   "metadata": {},
   "source": [
    "#### L'encodage OneHot est ici meilleur sur chacune des métriques mais est 40 fois plus long : 4.0s contre 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506b32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1720.49\n",
      "RMSE : 2992.19\n",
      "R²   : 0.3517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Creating feature\n",
    "X = df_one_hot.drop(columns='prix_au_m2')\n",
    "y = df_one_hot['prix_au_m2']\n",
    "\n",
    "# Spliting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = root_mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60baa1a4",
   "metadata": {},
   "source": [
    "#### Saving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ed907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "\n",
    "# Creating feature\n",
    "X = df_one_hot.drop(columns='prix_au_m2')\n",
    "y = df_one_hot['prix_au_m2']\n",
    "\n",
    "# Training the model on all the data for the app\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"../models/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "with open(\"../models/model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582613aa",
   "metadata": {},
   "source": [
    "## Test avec normalisation aussi (à mettre dans un autre notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = df.drop(columns=\"prix_au_m2\")\n",
    "y = df[\"prix_au_m2\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['adresse_nom_voie', 'arrondissement']),\n",
    "    ('num', StandardScaler(), ['adresse_numero', 'adresse_code_voie',\n",
    "       'lot1_surface_carrez', 'surface_reelle_bati',\n",
    "       'nombre_pieces_principales', 'longitude', 'latitude',\n",
    "       'année', 'arrondissement'])  \n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', DecisionTreeRegressor(max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "rmse = root_mean_squared_error(y_pred,y_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE : {mae}\\n\")\n",
    "print(f\"RMSE: {rmse}\\n\")\n",
    "print(f\"R2 : {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb419f",
   "metadata": {},
   "source": [
    "#### A priori la normalisation des données n'améliore pas du tout les prédictions sur un arbre de Décision. Ce qui semble être le cas théoriquement. En revanche on lit que cela devrait améliorer l'erreur sur un KNN ou resaux de neurones. Regardons donc cela sur KNN. On pourra comparer à l'erreur que l'on a sans normalisation et sans OneHot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = df.drop(columns=\"prix_au_m2\")\n",
    "y = df[\"prix_au_m2\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['adresse_nom_voie', 'arrondissement']),\n",
    "    ('num', StandardScaler(), ['adresse_numero', 'adresse_code_voie',\n",
    "       'lot1_surface_carrez', 'surface_reelle_bati',\n",
    "       'nombre_pieces_principales', 'longitude', 'latitude',\n",
    "       'année', 'arrondissement'])  \n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=25, weights='distance'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "rmse = root_mean_squared_error(y_pred,y_test)\n",
    "r2 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(f\"MAE : {mae}\\n\")\n",
    "print(f\"RMSE: {rmse}\\n\")\n",
    "print(f\"R2 : {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb842f7",
   "metadata": {},
   "source": [
    "#### On a carrément une meilleure erreur avec la normalisation sur KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
